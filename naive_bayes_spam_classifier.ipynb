{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“§ Clasificarea Spam-ului cu Naive Bayes\n",
    "## DemonstraÈ›ie PracticÄƒ: De la Teoria ProbabilitÄƒÈ›ii la AI Aplicat\n",
    "\n",
    "**Obiective:**\n",
    "- ğŸ¯ ÃnÈ›elegerea fundamentelor matematice ale Teoremei Bayes\n",
    "- ğŸ”§ Implementare de la zero a algoritmului Naive Bayes\n",
    "- ğŸ“Š Vizualizarea rezultatelor È™i evaluarea performanÈ›ei\n",
    "- ğŸ’¼ AplicaÈ›ie practicÄƒ pe date reale de spam\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Fundamente Teoretice\n",
    "\n",
    "### Teorema Bayes\n",
    "\n",
    "Teorema lui Bayes, formulatÄƒ Ã®n 1763, este fundamentul inferenÈ›ei statistice:\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\times P(H)}{P(E)}$$\n",
    "\n",
    "Unde:\n",
    "- **P(H|E)** = Probabilitatea **posterioarÄƒ** (ipoteza H datÄƒ evidenÈ›a E)\n",
    "- **P(E|H)** = **Likelihood** (probabilitatea evidenÈ›ei E dacÄƒ H este adevÄƒrat)\n",
    "- **P(H)** = Probabilitatea **priori** (credinÈ›a iniÈ›ialÄƒ Ã®n H)\n",
    "- **P(E)** = Probabilitatea evidenÈ›ei (constantÄƒ de normalizare)\n",
    "\n",
    "### AplicaÈ›ie la Clasificarea Spam\n",
    "\n",
    "Pentru clasificarea unui email cu cuvintele Wâ‚, Wâ‚‚, ..., Wâ‚™:\n",
    "\n",
    "$$P(Spam|W_1, W_2, ..., W_n) = \\frac{P(W_1, W_2, ..., W_n|Spam) \\times P(Spam)}{P(W_1, W_2, ..., W_n)}$$\n",
    "\n",
    "**AsumpÈ›ia Naive:** Cuvintele sunt independente condiÈ›ionat de clasÄƒ:\n",
    "\n",
    "$$P(W_1, W_2, ..., W_n|Spam) = \\prod_{i=1}^{n} P(W_i|Spam)$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importuri necesare\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurare vizualizÄƒri\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Biblioteci importate cu succes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Dataset de Spam Real\n",
    "\n",
    "Vom crea un dataset realist de mesaje spam È™i ham (non-spam):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de exemple - mesaje spam È™i ham Ã®n romÃ¢nÄƒ È™i englezÄƒ\n",
    "spam_messages = [\n",
    "    \"FELICITÄ‚RI! Ai cÃ¢È™tigat 1000 EURO! Click aici ACUM pentru a revendica premiul!\",\n",
    "    \"OfertÄƒ LIMITATÄ‚! CumpÄƒrÄƒ Viagra acum cu 90% REDUCERE!\",\n",
    "    \"Ai fost selectat pentru un PREMIU CASH de 5000 EUR! Click aici!\",\n",
    "    \"FREE MONEY! Win big prizes! Click now!\",\n",
    "    \"CÃ¢È™tigÄƒ bani rapid de acasÄƒ! FÄƒrÄƒ investiÈ›ie! Click aici!\",\n",
    "    \"URGENT: Contul tÄƒu a fost blocat. Click pentru a reactiva ACUM!\",\n",
    "    \"Congratulations! You won a FREE iPhone! Claim now!\",\n",
    "    \"Make money fast! Work from home! No experience needed!\",\n",
    "    \"SlÄƒbeÈ™te 10 kg Ã®n 7 zile! Pastile MAGICE! ComandÄƒ acum!\",\n",
    "    \"CASINO ONLINE - Bonus 1000 EUR la prima depunere! JoacÄƒ acum!\",\n",
    "    \"Credit rapid fÄƒrÄƒ acte! Aprobat Ã®n 5 minute! Click aici!\",\n",
    "    \"Winner! You have been selected for cash prize! Act now!\",\n",
    "    \"CumpÄƒrÄƒ followeri Instagram! 10000 followeri doar 50 EUR!\",\n",
    "    \"OFERTÄ‚ È˜OCANTÄ‚! Rolex original doar 99 EUR! Stock limitat!\",\n",
    "    \"CÃ¢È™tigÄƒ bani din reclame! 500 EUR/zi garantat!\",\n",
    "]\n",
    "\n",
    "ham_messages = [\n",
    "    \"BunÄƒ! Ne vedem mÃ¢ine la cafea?\",\n",
    "    \"Èši-am trimis raportul pe email. VerificÄƒ te rog.\",\n",
    "    \"Meetingul de astÄƒzi este amÃ¢nat pentru mÃ¢ine la 10:00.\",\n",
    "    \"Hi, how are you doing today?\",\n",
    "    \"Ai terminat proiectul la statisticÄƒ? SÄƒ discutÄƒm.\",\n",
    "    \"DocumentaÈ›ia pentru cursul de AI este disponibilÄƒ pe platformÄƒ.\",\n",
    "    \"Can we schedule a call for tomorrow afternoon?\",\n",
    "    \"MulÈ›umesc pentru ajutor cu tema! A fost foarte util.\",\n",
    "    \"ConferinÈ›a despre Machine Learning este pe 15 martie.\",\n",
    "    \"Your order has been shipped. Tracking number: ABC123.\",\n",
    "    \"BunÄƒ seara! Ai primit notiÈ›ele de la curs?\",\n",
    "    \"Team meeting at 3 PM in conference room B.\",\n",
    "    \"Ar fi bine sÄƒ ne pregÄƒtim pentru examen Ã®mpreunÄƒ.\",\n",
    "    \"The project deadline has been extended by one week.\",\n",
    "    \"MulÈ›umesc pentru recomandarea de carte! O sÄƒ o citesc.\",\n",
    "]\n",
    "\n",
    "# Crearea dataframe-ului\n",
    "data = pd.DataFrame({\n",
    "    'message': spam_messages + ham_messages,\n",
    "    'label': ['spam'] * len(spam_messages) + ['ham'] * len(ham_messages)\n",
    "})\n",
    "\n",
    "# Shuffle dataset\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset creat: {len(data)} mesaje\")\n",
    "print(f\"   - Spam: {sum(data['label'] == 'spam')} mesaje\")\n",
    "print(f\"   - Ham: {sum(data['label'] == 'ham')} mesaje\")\n",
    "print(\"\\nğŸ” Primele 5 exemple:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Preprocesarea Textului\n",
    "\n",
    "TransformÄƒm textul Ã®n format utilizabil pentru algoritm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesare text:\n",
    "    1. Convertire la lowercase\n",
    "    2. Eliminare caractere speciale\n",
    "    3. Tokenizare Ã®n cuvinte\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # PÄƒstreazÄƒ doar litere È™i spaÈ›ii\n",
    "    text = re.sub(r'[^a-zÄƒÃ¢Ã®È™È›\\s]', '', text)\n",
    "    \n",
    "    # Tokenizare\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Aplicare preprocesare\n",
    "data['tokens'] = data['message'].apply(preprocess_text)\n",
    "\n",
    "# Exemplu de preprocesare\n",
    "print(\"ğŸ“ Exemplu de preprocesare:\")\n",
    "print(f\"\\nOriginal: {data.iloc[0]['message']}\")\n",
    "print(f\"Tokenizat: {data.iloc[0]['tokens']}\")\n",
    "print(f\"Label: {data.iloc[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Implementare Naive Bayes de la Zero\n",
    "\n",
    "### Algoritmul pas cu pas:\n",
    "\n",
    "1. **Training:** CalculeazÄƒ probabilitÄƒÈ›i pentru fiecare cuvÃ¢nt Ã®n spam vs ham\n",
    "2. **Prediction:** AplicÄƒ Teorema Bayes pentru mesaj nou\n",
    "3. **Smoothing:** AdaugÄƒ Laplace smoothing pentru cuvinte noi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \"\"\"\n",
    "    Implementare Naive Bayes de la zero pentru clasificarea spam\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Parametru pentru Laplace smoothing (evitÄƒ probabilitÄƒÈ›i = 0)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.class_probs = {}  # P(spam) È™i P(ham)\n",
    "        self.word_probs = {}   # P(word|spam) È™i P(word|ham)\n",
    "        self.vocabulary = set()\n",
    "        \n",
    "    def fit(self, messages, labels):\n",
    "        \"\"\"\n",
    "        Antrenare: CalculeazÄƒ probabilitÄƒÈ›ile din datele de training\n",
    "        \"\"\"\n",
    "        # 1. CalculeazÄƒ probabilitÄƒÈ›ile claselor: P(spam) È™i P(ham)\n",
    "        total_messages = len(labels)\n",
    "        self.class_probs['spam'] = sum(labels == 'spam') / total_messages\n",
    "        self.class_probs['ham'] = sum(labels == 'ham') / total_messages\n",
    "        \n",
    "        # 2. ConstruieÈ™te vocabularul È™i numÄƒrÄƒ apariÈ›ii cuvinte\n",
    "        word_counts = {'spam': Counter(), 'ham': Counter()}\n",
    "        \n",
    "        for message, label in zip(messages, labels):\n",
    "            for word in message:\n",
    "                self.vocabulary.add(word)\n",
    "                word_counts[label][word] += 1\n",
    "        \n",
    "        # 3. CalculeazÄƒ P(word|class) cu Laplace smoothing\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        \n",
    "        for class_name in ['spam', 'ham']:\n",
    "            self.word_probs[class_name] = {}\n",
    "            total_words = sum(word_counts[class_name].values())\n",
    "            \n",
    "            for word in self.vocabulary:\n",
    "                count = word_counts[class_name][word]\n",
    "                # Laplace smoothing: (count + alpha) / (total + alpha * vocab_size)\n",
    "                self.word_probs[class_name][word] = \\\n",
    "                    (count + self.alpha) / (total_words + self.alpha * vocab_size)\n",
    "        \n",
    "        print(f\"âœ… Model antrenat!\")\n",
    "        print(f\"   - Vocabular: {vocab_size} cuvinte unice\")\n",
    "        print(f\"   - P(spam) = {self.class_probs['spam']:.3f}\")\n",
    "        print(f\"   - P(ham) = {self.class_probs['ham']:.3f}\")\n",
    "    \n",
    "    def predict_proba(self, message):\n",
    "        \"\"\"\n",
    "        CalculeazÄƒ probabilitÄƒÈ›ile P(spam|message) È™i P(ham|message)\n",
    "        \"\"\"\n",
    "        # CalculeazÄƒ log probabilitÄƒÈ›i (previne underflow numeric)\n",
    "        log_probs = {}\n",
    "        \n",
    "        for class_name in ['spam', 'ham']:\n",
    "            # Start cu log(P(class))\n",
    "            log_prob = np.log(self.class_probs[class_name])\n",
    "            \n",
    "            # AdaugÄƒ log(P(word|class)) pentru fiecare cuvÃ¢nt\n",
    "            for word in message:\n",
    "                if word in self.vocabulary:\n",
    "                    log_prob += np.log(self.word_probs[class_name][word])\n",
    "            \n",
    "            log_probs[class_name] = log_prob\n",
    "        \n",
    "        # ConverteÈ™te Ã®napoi din log space (normalizare)\n",
    "        max_log_prob = max(log_probs.values())\n",
    "        probs = {}\n",
    "        \n",
    "        for class_name in ['spam', 'ham']:\n",
    "            probs[class_name] = np.exp(log_probs[class_name] - max_log_prob)\n",
    "        \n",
    "        # Normalizare la sumÄƒ = 1\n",
    "        total = sum(probs.values())\n",
    "        probs = {k: v/total for k, v in probs.items()}\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def predict(self, message):\n",
    "        \"\"\"\n",
    "        PredicÈ›ie clasÄƒ (spam sau ham)\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(message)\n",
    "        return 'spam' if probs['spam'] > probs['ham'] else 'ham'\n",
    "    \n",
    "    def get_top_words(self, class_name, n=10):\n",
    "        \"\"\"\n",
    "        ReturneazÄƒ cele mai indicative n cuvinte pentru o clasÄƒ\n",
    "        \"\"\"\n",
    "        word_scores = {}\n",
    "        \n",
    "        for word in self.vocabulary:\n",
    "            # CalculeazÄƒ log ratio: log(P(word|class) / P(word|other_class))\n",
    "            other_class = 'ham' if class_name == 'spam' else 'spam'\n",
    "            ratio = self.word_probs[class_name][word] / self.word_probs[other_class][word]\n",
    "            word_scores[word] = np.log(ratio)\n",
    "        \n",
    "        # SorteazÄƒ È™i returneazÄƒ top N\n",
    "        top_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "        return top_words\n",
    "\n",
    "print(\"âœ… Clasa NaiveBayesClassifier definitÄƒ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Antrenare È™i Testare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['tokens'].values, \n",
    "    data['label'].values,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=data['label']\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Split dataset:\")\n",
    "print(f\"   Training: {len(X_train)} mesaje\")\n",
    "print(f\"   Testing: {len(X_test)} mesaje\")\n",
    "\n",
    "# Antrenare model\n",
    "print(\"\\nğŸ”§ Antrenare model...\")\n",
    "nb_classifier = NaiveBayesClassifier(alpha=1.0)\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Evaluare PerformanÈ›Äƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PredicÈ›ii pe setul de test\n",
    "y_pred = [nb_classifier.predict(message) for message in X_test]\n",
    "y_pred_proba = [nb_classifier.predict_proba(message)['spam'] for message in X_test]\n",
    "\n",
    "# AcurateÈ›e\n",
    "accuracy = np.mean(np.array(y_pred) == y_test)\n",
    "print(f\"ğŸ¯ AcurateÈ›e: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Raport de clasificare detaliat\n",
    "print(\"\\nğŸ“Š Raport de Clasificare:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ VizualizÄƒri Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurare plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('ğŸ“Š AnalizÄƒ CompletÄƒ Naive Bayes Spam Classifier', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Matricea de Confuzie\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['ham', 'spam'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "axes[0, 0].set_title('Matricea de Confuzie', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('AdevÄƒrat')\n",
    "axes[0, 0].set_xlabel('Prezis')\n",
    "\n",
    "# 2. DistribuÈ›ia ProbabilitÄƒÈ›ilor\n",
    "spam_probs = [p for p, label in zip(y_pred_proba, y_test) if label == 'spam']\n",
    "ham_probs = [p for p, label in zip(y_pred_proba, y_test) if label == 'ham']\n",
    "\n",
    "axes[0, 1].hist(spam_probs, bins=10, alpha=0.6, label='Spam Real', color='red', edgecolor='black')\n",
    "axes[0, 1].hist(ham_probs, bins=10, alpha=0.6, label='Ham Real', color='green', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('P(Spam)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('FrecvenÈ›Äƒ', fontsize=12)\n",
    "axes[0, 1].set_title('DistribuÈ›ia ProbabilitÄƒÈ›ilor de Spam', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Top Cuvinte Spam\n",
    "top_spam_words = nb_classifier.get_top_words('spam', n=10)\n",
    "words_spam = [w[0] for w in top_spam_words]\n",
    "scores_spam = [w[1] for w in top_spam_words]\n",
    "\n",
    "axes[1, 0].barh(words_spam, scores_spam, color='crimson', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Log Likelihood Ratio', fontsize=12)\n",
    "axes[1, 0].set_title('Top 10 Cuvinte Indicative pentru SPAM', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Top Cuvinte Ham\n",
    "top_ham_words = nb_classifier.get_top_words('ham', n=10)\n",
    "words_ham = [w[0] for w in top_ham_words]\n",
    "scores_ham = [w[1] for w in top_ham_words]\n",
    "\n",
    "axes[1, 1].barh(words_ham, scores_ham, color='mediumseagreen', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Log Likelihood Ratio', fontsize=12)\n",
    "axes[1, 1].set_title('Top 10 Cuvinte Indicative pentru HAM', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… VizualizÄƒri generate cu succes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Curba ROC È™i AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CalculeazÄƒ curba ROC\n",
    "y_test_binary = (y_test == 'spam').astype(int)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ğŸ“ˆ Curba ROC - Naive Bayes Spam Classifier', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ¯ AUC Score: {roc_auc:.4f}\")\n",
    "print(\"   â†’ 0.5 = clasificare aleatorie\")\n",
    "print(\"   â†’ 1.0 = clasificare perfectÄƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Test Interactiv pe Mesaje Noi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_message(message):\n",
    "    \"\"\"\n",
    "    AnalizeazÄƒ un mesaj nou È™i afiÈ™eazÄƒ detalii despre predicÈ›ie\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ğŸ“§ Mesaj: {message}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Preprocesare\n",
    "    tokens = preprocess_text(message)\n",
    "    print(f\"\\nğŸ”¤ Tokens: {tokens}\")\n",
    "    \n",
    "    # PredicÈ›ie\n",
    "    probs = nb_classifier.predict_proba(tokens)\n",
    "    prediction = nb_classifier.predict(tokens)\n",
    "    \n",
    "    # AfiÈ™are rezultate\n",
    "    print(f\"\\nğŸ“Š ProbabilitÄƒÈ›i:\")\n",
    "    print(f\"   P(Spam|mesaj) = {probs['spam']:.4f} ({probs['spam']*100:.2f}%)\")\n",
    "    print(f\"   P(Ham|mesaj)  = {probs['ham']:.4f} ({probs['ham']*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ PredicÈ›ie: {'ğŸš¨ SPAM' if prediction == 'spam' else 'âœ… HAM (legitim)'}\")\n",
    "    \n",
    "    # Vizualizare probabilitÄƒÈ›i\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    colors = ['crimson' if prediction == 'spam' else 'mediumseagreen', \n",
    "              'lightcoral' if prediction == 'spam' else 'lightgreen']\n",
    "    plt.bar(['Spam', 'Ham'], [probs['spam'], probs['ham']], \n",
    "            color=colors, edgecolor='black', linewidth=2)\n",
    "    plt.ylabel('Probabilitate', fontsize=12)\n",
    "    plt.title(f\"PredicÈ›ie: {'SPAM' if prediction == 'spam' else 'HAM'}\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # AdaugÄƒ valori pe bare\n",
    "    for i, (cat, prob) in enumerate(zip(['Spam', 'Ham'], [probs['spam'], probs['ham']])):\n",
    "        plt.text(i, prob + 0.02, f'{prob:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Testare pe mesaje noi\n",
    "test_messages = [\n",
    "    \"FELICITÄ‚RI! Ai cÃ¢È™tigat un iPhone 15 GRATUIT! Click ACUM!\",\n",
    "    \"BunÄƒ! Ne vedem la meeting mÃ¢ine la ora 10?\",\n",
    "    \"URGENT: Contul tÄƒu a expirat. ReactiveazÄƒ ACUM pentru bonus 1000 EUR!\",\n",
    "    \"Raportul de statisticÄƒ este gata. L-am Ã®ncÄƒrcat pe drive.\",\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    analyze_message(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ ComparaÈ›ie cu Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# CreeazÄƒ pipeline sklearn\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(lowercase=True, token_pattern=r'[a-zÄƒÃ¢Ã®È™È›]+')),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Antrenare\n",
    "X_train_text = [' '.join(tokens) for tokens in X_train]\n",
    "X_test_text = [' '.join(tokens) for tokens in X_test]\n",
    "\n",
    "sklearn_pipeline.fit(X_train_text, y_train)\n",
    "y_pred_sklearn = sklearn_pipeline.predict(X_test_text)\n",
    "accuracy_sklearn = np.mean(y_pred_sklearn == y_test)\n",
    "\n",
    "# ComparaÈ›ie\n",
    "print(\"ğŸ“Š ComparaÈ›ie PerformanÈ›Äƒ:\\n\")\n",
    "print(f\"{'Model':<30} {'AcurateÈ›e':<15}\")\n",
    "print(\"=\"*45)\n",
    "print(f\"{'Implementare Custom':<30} {accuracy * 100:>13.2f}%\")\n",
    "print(f\"{'Sklearn MultinomialNB':<30} {accuracy_sklearn * 100:>13.2f}%\")\n",
    "print(\"=\"*45)\n",
    "print(f\"\\nâœ… DiferenÈ›Äƒ: {abs(accuracy - accuracy_sklearn) * 100:.2f}%\")\n",
    "print(\"\\nğŸ’¡ Implementarea noastrÄƒ oferÄƒ rezultate similare cu sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Concluzii È™i Insights\n",
    "\n",
    "### Ce am Ã®nvÄƒÈ›at:\n",
    "\n",
    "1. **Teoria Ã®n PracticÄƒ:**\n",
    "   - Teorema Bayes nu este doar matematicÄƒ abstractÄƒ - este fundamentul unor sisteme AI practice\n",
    "   - AsumpÈ›ia de independenÈ›Äƒ (\"naive\") funcÈ›ioneazÄƒ surprinzÄƒtor de bine Ã®n practicÄƒ\n",
    "\n",
    "2. **ImportanÈ›a Smoothing-ului:**\n",
    "   - Laplace smoothing previne probabilitÄƒÈ›i = 0 pentru cuvinte noi\n",
    "   - Parametrul Î± controleazÄƒ cÃ¢t de mult \"Ã®ncredere\" dÄƒm datelor vs distribuÈ›iei uniforme\n",
    "\n",
    "3. **PerformanÈ›Äƒ:**\n",
    "   - Naive Bayes este rapid È™i eficient\n",
    "   - FuncÈ›ioneazÄƒ bine chiar cu dataset-uri mici\n",
    "   - ScaleazÄƒ excelent la date mari (complexitate O(n))\n",
    "\n",
    "4. **LimitÄƒri:**\n",
    "   - AsumpÈ›ia de independenÈ›Äƒ este adesea violatÄƒ Ã®n realitate\n",
    "   - Nu capteazÄƒ relaÈ›ii contextuale complexe\n",
    "   - Pentru texte complexe, modele mai avansate (LSTM, Transformers) pot performa mai bine\n",
    "\n",
    "### AplicaÈ›ii Practice:\n",
    "- âœ‰ï¸ Filtrare spam email\n",
    "- ğŸ’¬ Analiza sentimentului\n",
    "- ğŸ“° Clasificare documente\n",
    "- ğŸ¥ Diagnostic medical (cu date categorice)\n",
    "- ğŸ” Sisteme de recomandare\n",
    "\n",
    "### Next Steps:\n",
    "1. Extindere cu TF-IDF Ã®n loc de simple count\n",
    "2. Experimentare cu n-grams (bigrams, trigrams)\n",
    "3. Combinare cu alte algoritmi (ensemble methods)\n",
    "4. Deployment ca API web cu Flask/FastAPI\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“– ReferinÈ›e:**\n",
    "- Bishop, C. M. (2006). Pattern Recognition and Machine Learning\n",
    "- Manning, C. D., Raghavan, P., & SchÃ¼tze, H. (2008). Introduction to Information Retrieval\n",
    "- Russell, S., & Norvig, P. (2020). Artificial Intelligence: A Modern Approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
